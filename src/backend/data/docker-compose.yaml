services:
  kafka:
    image: apache/kafka:4.0.0
    container_name: kafka
    volumes:
      - kafka-data:/var/lib/kafka/data
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://localhost:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
      KAFKA_LOG_RETENTION_HOURS: 168 # 7 day retention policy
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 10000
      KAFKA_GROUP_MAX_SESSION_TIMEOUT_MS: 600000
    healthcheck:
      test: [ "CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list" ]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - messaging

  kafka-init:
    image: apache/kafka:4.0.0
    container_name: arxiv_kafka_init
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      sh -c "
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --topic parsing --bootstrap-server kafka:9092 --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --topic extracting --bootstrap-server kafka:9092 --partitions 3 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --topic chunking --bootstrap-server kafka:9092 --partitions 3 --replication-factor 1
        echo 'Topics created successfully'
      "
    networks:
      - messaging

  harvester:
    container_name: arxiv_harvester
    build:
      context: .
      dockerfile: ./harvester/Dockerfile
    env_file: ./.env
    command: python harvester.py
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      kafka:
        condition: service_healthy
      mongo:
        condition: service_healthy
    volumes:
      - ./harvester/data:/app/data
    networks:
      - messaging
      - database

  parser:
    build:
      context: .
      dockerfile: ./pdf_parser/Dockerfile
    env_file: ./.env
    command: >
      sh -c "
        sleep $$((RANDOM % 30 + 5)) &&
        python parser.py
      "
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      kafka:
        condition: service_healthy
      mongo:
        condition: service_started
      kafka-init:
        condition: service_completed_successfully
    networks:
      - database
      - messaging
    deploy:
      replicas: 4

  mongo:
    image: mongo:latest
    container_name: arxiv_mongo
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: pass
      MONGO_INITDB_DATABASE: arxiv_db
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: [ "CMD-SHELL", "mongosh -u admin -p pass --eval 'db.adminCommand(\"ping\")' || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - database

  loader:
    build:
      context: .
      dockerfile: ./processing/Dockerfile.loader
    container_name: arxiv_doc_loader
    env_file: ./.env
    command: [ "--collection", "${COLLECTION_NAME}", "--topic", "${TOPIC_NAME}" ]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      mongo:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - messaging
      - database
    restart: "no"

  chunker:
    build:
      context: .
      dockerfile: ./processing/Dockerfile.chunking
    env_file: ./.env
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    command: [ "python", "chunking.py", "--consumer-group", "${CONSUMER_GROUP_NAME}", "--collection-name", "${COLLECTION_NAME}", "--chunking-strategy", "${CHUNKING_STRATEGY}" ]
    depends_on:
      mongo:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - messaging
      - database
    deploy:
      replicas: 3

  kwe:
    build:
      context: .
      dockerfile: ./processing/Dockerfile.kw
    env_file: ./.env
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      mongo:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - messaging
      - database

  vectorstore:
    build:
      context: .
      dockerfile: ./vectorstore/Dockerfile
    container_name: arxiv_vectorstore_builder
    env_file: ./.env
    command: [ "--collection", "${COLLECTION_NAME}", "--index-type", "${FAISS_INDEX_TYPE:-flat}", "--embedding-model", "${EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}", "--output-path", "/app/vectorstore_data", "--batch-size", "${BATCH_SIZE:-100}", "--limit", "200", "--storage-type", "mongodb" ]
    depends_on:
      mongo:
        condition: service_healthy
    networks:
      - database
    restart: "no"

volumes:
  kafka-data:
    driver: local
  mongo-data:
    driver: local

networks:
  database:
    driver: bridge
  messaging:
    driver: bridge
