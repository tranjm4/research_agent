{"execution_time": 1.0940994170377962, "execution_date": "2025-07-17 02:43:03", "output": "'Document 1: In this study, we conducted a comprehensive data collection on the 2022 Qatar FIFA World Cup event and used a multilayer network approach to visualize the main topics, while considering their context and meaning relationships. We structured the data into layers that corresponded with the stages of the tournament and utilized Gephi software to generate the multilayer networks. Our visualizations displayed both the relationships between topics and words, showing the word-context relationship, as well as the dynamics and changes over time by layer of the most frequently discussed topics. (https://arxiv.org/abs/2401.12228)\\nDocument 2: Twitter is a social media platform bridging most countries and allows real-time news discovery. Since the tweets on Twitter are usually short and express public feelings, thus provide a source for opinion mining and sentiment analysis for global events. This paper proposed an effective solution, in providing a sentiment on tweets related to the FIFA World Cup. At least 130k tweets, as the first in the community, are collected and implemented as a dataset to evaluate the performance of the proposed machine learning solution. These tweets are collected with the related hashtags and keywords of the Qatar World Cup 2022. The Vader algorithm is used in this paper for sentiment analysis. Through the machine learning method and collected Twitter tweets, we discovered the sentiments and fun facts of several aspects important to the period before the World Cup. The result shows people are positive to the opening of the World Cup. (https://arxiv.org/abs/2306.16049)\\nDocument 3: Qualifications for several world championships in sports are organised such that distinct sets of teams play in their own tournament for a predetermined number of slots. Inspired by a recent work studying the problem with the tools from the literature on fair allocation, this paper provides an alternative approach based on historical matches between these sets of teams. We focus on the FIFA World Cup due to the existence of an official rating system and its recent expansion to 48 teams, as well as to allow for a comparison with the already suggested allocations. Our proposal extends the methodology of the FIFA World Ranking to compare the strengths of five confederations. Various allocations are presented depending on the length of the sample, the set of teams considered, as well as the frequency of rating updates. The results show that more European and South American teams should play in the FIFA World Cup. The ranking of continents by the number of deserved slots is different from the ranking implied by FIFA policy. We recommend allocating at least some slots transparently, based on historical performances, similar to the access list of the UEFA Champions League. (https://arxiv.org/abs/2310.19100)\\nDocument 4: The Fifth International Conference on Applied Category Theory took place at the University of Strathclyde in Glasgow, Scotland on 18-22 July 2022. This conference follows the previous meetings at Leiden (2018), Oxford (2019), MIT (2020, fully online), and Cambridge (2021). The conference comprised 59 contributed talks, a poster session, an industry showcase session, and a session where junior researchers who had attended the Adjoint School presented the results of their research at the school. Information regarding the conference may be found at (https://msp.cis.strath.ac.uk/act2022).\\n  The contributions to ACT2022 ranged from pure to applied and included contributions in a wide range of disciplines in science and engineering. ACT2022 included talks in linguistics, functional programming, classical mechanics, quantum physics, probability theory, electrical engineering, epidemiology, thermodynamics, engineering, and logic. ACT2022 was sponsored by Huawei, Protocol Labs, Cambridge Quantum, Conexus, Topos, and SICSA (Scottish Informatics and Computer Science Alliance).\\n  Submission to ACT2022 had three tracks: extended abstracts, software demonstrations, and proceedings. The extended abstract and software demonstration submissions had a page limit of 2 pages, and the proceedings track had a page limit of 14 pages. Only papers submitted to the proceedings track were considered for publication in this volume. In total, there were 97 submissions, of which 59 were accepted for presentation and 24 for publication in this volume. Publication of accepted submissions in the proceedings was determined by personal choice of the authors and not based on quality. Each submission received a review from three different members of the programming committee, and papers were selected based on discussion and consensus by these reviewers. (https://arxiv.org/abs/2307.15519)\\nDocument 5: This volume contains the proceedings of DCM 2023, the 13th International Workshop on Developments in Computational Models held on 2 July 2023 in Rome, Italy. DCM 2023 was organised as a one-day satellite event of FSCD 2023, the 8th International Conference on Formal Structures for Computation and Deduction. The aim of this workshop is to bring together researchers who are currently developing new computation models or new features for traditional computation models, in order to foster their interaction, to provide a forum for presenting new ideas and work in progress, and to enable newcomers to learn about current activities in this area. (https://arxiv.org/abs/2409.19298)'", "args": "('Club World Cup 2025 winner',)", "kwargs": "{}", "model_name": "cross-encoder/ms-marco-MiniLM-L-12-v2", "type": "retriever", "version_name": "retriever/cross-encoder/ms-marco-MiniLM-L-12-v2/v1"}
{"execution_time": 1.7164451659773476, "execution_date": "2025-07-17 02:52:48", "output": "'Document 1: With the rapid development of artificial intelligence technology, large language models (LLMs) have become a hot research topic. Education plays an important role in human social development and progress. Traditional education faces challenges such as individual student differences, insufficient allocation of teaching resources, and assessment of teaching effectiveness. Therefore, the applications of LLMs in the field of digital/smart education have broad prospects. The research on educational large models (EduLLMs) is constantly evolving, providing new methods and approaches to achieve personalized learning, intelligent tutoring, and educational assessment goals, thereby improving the quality of education and the learning experience. This article aims to investigate and summarize the application of LLMs in smart education. It first introduces the research background and motivation of LLMs and explains the essence of LLMs. It then discusses the relationship between digital education and EduLLMs and summarizes the current research status of educational large models. The main contributions are the systematic summary and vision of the research background, motivation, and application of large models for education (LLM4Edu). By reviewing existing research, this article provides guidance and insights for educators, researchers, and policy-makers to gain a deep understanding of the potential and challenges of LLM4Edu. It further provides guidance for further advancing the development and application of LLM4Edu, while still facing technical, ethical, and practical challenges requiring further research and exploration. (https://arxiv.org/abs/2311.13160)\\nDocument 2: The advent of Large Language Models (LLMs) has brought in a new era of possibilities in the realm of education. This survey paper summarizes the various technologies of LLMs in educational settings from multifaceted perspectives, encompassing student and teacher assistance, adaptive learning, and commercial tools. We systematically review the technological advancements in each perspective, organize related datasets and benchmarks, and identify the risks and challenges associated with deploying LLMs in education. Furthermore, we outline future research opportunities, highlighting the potential promising directions. Our survey aims to provide a comprehensive technological picture for educators, researchers, and policymakers to harness the power of LLMs to revolutionize educational practices and foster a more effective personalized learning environment. (https://arxiv.org/abs/2403.18105)\\nDocument 3: In recent years, the rapid development of artificial intelligence technology, especially the emergence of large language models (LLMs) such as ChatGPT, has presented significant prospects for application in the field of education. LLMs possess the capability to interpret knowledge, answer questions, and consider context, thus providing support for dialogic teaching to students. Therefore, an examination of the capacity of LLMs to effectively fulfill instructional roles, thereby facilitating student learning akin to human educators within dialogic teaching scenarios, is an exceptionally valuable research topic. This research recruited 34 undergraduate students as participants, who were randomly divided into two groups. The experimental group engaged in dialogic teaching using ChatGPT, while the control group interacted with human teachers. Both groups learned the histogram equalization unit in the information-related course \"Digital Image Processing\". The research findings show comparable scores between the two groups on the retention test. However, students who engaged in dialogue with ChatGPT exhibited lower performance on the transfer test. Electroencephalography data revealed that students who interacted with ChatGPT exhibited higher levels of cognitive activity, suggesting that ChatGPT could help students establish a knowledge foundation and stimulate cognitive activity. However, its strengths on promoting students. knowledge application and creativity were insignificant. Based upon the research findings, it is evident that ChatGPT cannot fully excel in fulfilling teaching tasks in the dialogue teaching in information related courses. Combining ChatGPT with traditional human teachers might be a more ideal approach. The synergistic use of both can provide students with more comprehensive learning support, thus contributing to enhancing the quality of teaching. (https://arxiv.org/abs/2403.16687)\\nDocument 4: The universal availability of ChatGPT and other similar tools since late 2022 has prompted tremendous public excitement and experimental effort about the potential of large language models (LLMs) to improve learning experience and outcomes, especially for learners from disadvantaged backgrounds. However, little research has systematically examined the real-world impacts of LLM availability on educational equity beyond theoretical projections and controlled studies of innovative LLM applications. To depict trends of post-LLM inequalities, we analyze 1,140,328 academic writing submissions from 16,791 college students across 2,391 courses between 2021 and 2024 at a public, minority-serving institution in the US. We find that students\\' overall writing quality gradually increased following the availability of LLMs and that the writing quality gaps between linguistically advantaged and disadvantaged students became increasingly narrower. However, this equitizing effect was more concentrated on students with higher socioeconomic status. These findings shed light on the digital divides in the era of LLMs and raise questions about the equity benefits of LLMs in early stages and highlight the need for researchers and practitioners on developing responsible practices to improve educational equity through LLMs. (https://arxiv.org/abs/2410.22282)\\nDocument 5: Structured science summaries or research contributions using properties or dimensions beyond traditional keywords enhances science findability. Current methods, such as those used by the Open Research Knowledge Graph (ORKG), involve manually curating properties to describe research papers\\' contributions in a structured manner, but this is labor-intensive and inconsistent between the domain expert human curators. We propose using Large Language Models (LLMs) to automatically suggest these properties. However, it\\'s essential to assess the readiness of LLMs like GPT-3.5, Llama 2, and Mistral for this task before application. Our study performs a comprehensive comparative analysis between ORKG\\'s manually curated properties and those generated by the aforementioned state-of-the-art LLMs. We evaluate LLM performance through four unique perspectives: semantic alignment and deviation with ORKG properties, fine-grained properties mapping accuracy, SciNCL embeddings-based cosine similarity, and expert surveys comparing manual annotations with LLM outputs. These evaluations occur within a multidisciplinary science setting. Overall, LLMs show potential as recommendation systems for structuring science, but further finetuning is recommended to improve their alignment with scientific tasks and mimicry of human expertise. (https://arxiv.org/abs/2405.02105)'", "args": "('Research articles on LLMs in K-12 education',)", "kwargs": "{}", "model_name": "cross-encoder/ms-marco-MiniLM-L-12-v2", "type": "retriever", "version_name": "retriever/cross-encoder/ms-marco-MiniLM-L-12-v2/v1"}
